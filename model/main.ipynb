{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m layers, Model\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import random_split\n",
    "import torch.optim as optim\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeapMotionDataset(Dataset):\n",
    "    def __init__(self, root_dir, seq_len=40, transform=None):\n",
    "        \"\"\"\n",
    "        Dataset pour les données du Leap Motion\n",
    "        \n",
    "        Args:\n",
    "            root_dir: Répertoire racine contenant les dossiers des personnes\n",
    "            seq_len: Longueur de la séquence à utiliser (nombre de frames)\n",
    "            transform: Transformations éventuelles\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.seq_len = seq_len\n",
    "        self.transform = transform\n",
    "        self.sequences = []\n",
    "        \n",
    "        # Parcourir la structure de données\n",
    "        person_folders = sorted([f for f in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, f))])\n",
    "        \n",
    "        for person_id, person_folder in enumerate(person_folders):\n",
    "            person_path = os.path.join(root_dir, person_folder)\n",
    "            \n",
    "            gesture_folders = sorted([f for f in os.listdir(person_path) if os.path.isdir(os.path.join(person_path, f))])\n",
    "            for gesture_folder in gesture_folders:\n",
    "                # Extraire l'ID du geste (g00 -> 0, g01 -> 1, etc.)\n",
    "                if gesture_folder.startswith('g') and len(gesture_folder) >= 3:\n",
    "                    try:\n",
    "                        gesture_id = int(gesture_folder[1:3])\n",
    "                    except ValueError:\n",
    "                        continue\n",
    "                        \n",
    "                    gesture_path = os.path.join(person_path, gesture_folder)\n",
    "                    \n",
    "                    repetition_folders = sorted([f for f in os.listdir(gesture_path) if os.path.isdir(os.path.join(gesture_path, f))])\n",
    "                    for repetition_folder in repetition_folders:\n",
    "                        try:\n",
    "                            repetition_id = int(repetition_folder)\n",
    "                        except ValueError:\n",
    "                            continue\n",
    "                            \n",
    "                        repetition_path = os.path.join(gesture_path, repetition_folder)\n",
    "                        tracking_path = os.path.join(repetition_path, 'leap_motion', 'tracking_data')\n",
    "                        \n",
    "                        if os.path.exists(tracking_path):\n",
    "                            json_files = sorted([f for f in os.listdir(tracking_path) if f.endswith('_js.json')])\n",
    "                            \n",
    "                            if len(json_files) >= self.seq_len:\n",
    "                                self.sequences.append({\n",
    "                                    'person_id': person_id,\n",
    "                                    'gesture_id': gesture_id,\n",
    "                                    'repetition_id': repetition_id,\n",
    "                                    'json_files': [os.path.join(tracking_path, f) for f in json_files[:self.seq_len]]\n",
    "                                })\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "    \n",
    "    def extract_hand_features(self, json_data):\n",
    "        \"\"\"Extraire les caractéristiques essentielles de la main depuis le JSON\"\"\"\n",
    "        features = []\n",
    "        \n",
    "        try:\n",
    "            # Si les données contiennent une main droite\n",
    "            if 'right_hand' in json_data['frame']:\n",
    "                hand = json_data['frame']['right_hand']\n",
    "                \n",
    "                # Position de la paume (3 coordonnées)\n",
    "                palm_pos = hand['palm_position'][:3]\n",
    "                features.extend(palm_pos)\n",
    "                \n",
    "                # Direction et normale de la paume (6 coordonnées)\n",
    "                features.extend(hand['direction'][:3])\n",
    "                features.extend(hand['palm_normal'][:3])\n",
    "                \n",
    "                # Positions des articulations des doigts\n",
    "                fingers = hand['fingers']\n",
    "                for finger_name in ['thumb', 'index', 'middle', 'ring', 'pinky']:\n",
    "                    if finger_name in fingers:\n",
    "                        finger = fingers[finger_name]\n",
    "                        for bone_name in ['metacarpal', 'proximal', 'intermediate', 'distal']:\n",
    "                            if bone_name in finger['bones']:\n",
    "                                bone = finger['bones'][bone_name]\n",
    "                                # Position de l'articulation (3 coordonnées)\n",
    "                                features.extend(bone['next_joint'][:3])\n",
    "            \n",
    "            # Ajouter des zéros si les caractéristiques sont manquantes\n",
    "            while len(features) < 64:  # Taille fixe des features\n",
    "                features.append(0.0)\n",
    "                \n",
    "            return np.array(features[:64])  # Limiter à 64 caractéristiques\n",
    "        \n",
    "        except (KeyError, IndexError) as e:\n",
    "            # Retourner un vecteur de zéros en cas d'erreur\n",
    "            print(f\"Erreur d'extraction: {e}\")\n",
    "            return np.zeros(64)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sequence = self.sequences[idx]\n",
    "        hand_features = []\n",
    "        \n",
    "        for json_file in sequence['json_files']:\n",
    "            try:\n",
    "                with open(json_file, 'r') as f:\n",
    "                    data = json.load(f)\n",
    "                    features = self.extract_hand_features(data)\n",
    "                    hand_features.append(features)\n",
    "            except (json.JSONDecodeError, FileNotFoundError) as e:\n",
    "                # En cas d'erreur, ajouter un vecteur de zéros\n",
    "                print(f\"Erreur de chargement {json_file}: {e}\")\n",
    "                hand_features.append(np.zeros(64))\n",
    "        \n",
    "        # Convertir en tensor\n",
    "        hand_features = np.array(hand_features)\n",
    "        hand_features = torch.tensor(hand_features, dtype=torch.float32)\n",
    "        \n",
    "        if self.transform:\n",
    "            hand_features = self.transform(hand_features)\n",
    "            \n",
    "        return {\n",
    "            'features': hand_features,\n",
    "            'gesture_id': torch.tensor(sequence['gesture_id'], dtype=torch.long),\n",
    "            'person_id': torch.tensor(sequence['person_id'], dtype=torch.long),\n",
    "            'repetition_id': torch.tensor(sequence['repetition_id'], dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class LeapMotionGCN(nn.Module):\n",
    "    def __init__(self, input_features=64, hidden_dim=128, num_classes=12):\n",
    "        super(LeapMotionGCN, self).__init__()\n",
    "        \n",
    "        # Couche d'embedding pour les caractéristiques de la main\n",
    "        self.embedding = nn.Sequential(\n",
    "            nn.Linear(input_features, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(hidden_dim)\n",
    "        )\n",
    "        \n",
    "        # GRU bidirectionnel pour la séquence temporelle\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=hidden_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=2,\n",
    "            batch_first=True,\n",
    "            bidirectional=True,\n",
    "            dropout=0.3\n",
    "        )\n",
    "        \n",
    "        # Attention\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, 1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "        # Classification finale\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(hidden_dim, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x shape: [batch_size, seq_len, input_features]\n",
    "        batch_size, seq_len, _ = x.size()\n",
    "        \n",
    "        # Reshape pour l'embedding\n",
    "        x_reshaped = x.reshape(batch_size * seq_len, -1)\n",
    "        embedded = self.embedding(x_reshaped)\n",
    "        \n",
    "        # Retour à la forme séquentielle\n",
    "        embedded = embedded.reshape(batch_size, seq_len, -1)\n",
    "        \n",
    "        # GRU\n",
    "        gru_out, _ = self.gru(embedded)\n",
    "        \n",
    "        # Attention\n",
    "        attn_weights = self.attention(gru_out).squeeze(-1)\n",
    "        attn_weights = torch.softmax(attn_weights, dim=1).unsqueeze(-1)\n",
    "        \n",
    "        # Contexte pondéré par l'attention\n",
    "        context = torch.sum(gru_out * attn_weights, dim=1)\n",
    "        \n",
    "        # Classification\n",
    "        output = self.classifier(context)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre total de séquences: 962\n"
     ]
    }
   ],
   "source": [
    "# Préparation des données\n",
    "dataset = LeapMotionDataset(root_dir='../leap_motion/train')\n",
    "print(f\"Nombre total de séquences: {len(dataset)}\")\n",
    "\n",
    "# Ajouter ce code pour identifier le nombre de classes\n",
    "unique_gestures = set()\n",
    "for sequence in dataset.sequences:\n",
    "    unique_gestures.add(sequence['gesture_id'])\n",
    "\n",
    "num_classes = len(unique_gestures)\n",
    "print(f\"Nombre de classes uniques: {num_classes}\")\n",
    "print(f\"IDs des classes: {sorted(list(unique_gestures))}\")\n",
    "\n",
    "# Diviser en train/val\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)\n",
    "\n",
    "# Modèle\n",
    "model = LeapMotionGCN(input_features=64, hidden_dim=128, num_classes=13)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=5, factor=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8f1e871a88c46ce95d648c8ec528e5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entraînement:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:\n",
      "Train Loss: 2.2724, Train Acc: 27.31%\n",
      "Val Loss: 2.3278, Val Acc: 25.39%\n",
      "Epoch 2/50:\n",
      "Train Loss: 1.2534, Train Acc: 61.90%\n",
      "Val Loss: 0.9931, Val Acc: 64.25%\n",
      "Epoch 3/50:\n",
      "Train Loss: 0.6945, Train Acc: 77.76%\n",
      "Val Loss: 0.6207, Val Acc: 72.54%\n",
      "Epoch 4/50:\n",
      "Train Loss: 0.4886, Train Acc: 83.62%\n",
      "Val Loss: 1.0511, Val Acc: 66.32%\n",
      "Epoch 5/50:\n",
      "Train Loss: 0.3544, Train Acc: 86.22%\n",
      "Val Loss: 1.2895, Val Acc: 58.03%\n",
      "Epoch 6/50:\n",
      "Train Loss: 0.6712, Train Acc: 89.21%\n",
      "Val Loss: 0.7123, Val Acc: 77.20%\n",
      "Epoch 7/50:\n",
      "Train Loss: 0.3153, Train Acc: 88.56%\n",
      "Val Loss: 0.4152, Val Acc: 87.56%\n",
      "Epoch 8/50:\n",
      "Train Loss: 0.2442, Train Acc: 91.42%\n",
      "Val Loss: 0.3319, Val Acc: 86.53%\n",
      "Epoch 9/50:\n",
      "Train Loss: 0.2084, Train Acc: 92.33%\n",
      "Val Loss: 0.3818, Val Acc: 84.97%\n",
      "Epoch 10/50:\n",
      "Train Loss: 0.1722, Train Acc: 93.24%\n",
      "Val Loss: 0.1755, Val Acc: 90.67%\n",
      "Epoch 11/50:\n",
      "Train Loss: 0.1443, Train Acc: 95.84%\n",
      "Val Loss: 0.2857, Val Acc: 87.05%\n",
      "Epoch 12/50:\n",
      "Train Loss: 0.1691, Train Acc: 94.02%\n",
      "Val Loss: 0.4436, Val Acc: 83.42%\n",
      "Epoch 13/50:\n",
      "Train Loss: 0.1190, Train Acc: 95.84%\n",
      "Val Loss: 0.1020, Val Acc: 96.37%\n",
      "Epoch 14/50:\n",
      "Train Loss: 0.1004, Train Acc: 96.75%\n",
      "Val Loss: 0.2529, Val Acc: 90.16%\n",
      "Epoch 15/50:\n",
      "Train Loss: 0.1216, Train Acc: 95.58%\n",
      "Val Loss: 0.3727, Val Acc: 88.08%\n",
      "Epoch 16/50:\n",
      "Train Loss: 0.1952, Train Acc: 95.19%\n",
      "Val Loss: 1.5745, Val Acc: 79.27%\n",
      "Epoch 17/50:\n",
      "Train Loss: 0.3244, Train Acc: 94.67%\n",
      "Val Loss: 2.6063, Val Acc: 66.32%\n",
      "Epoch 18/50:\n",
      "Train Loss: 0.2713, Train Acc: 91.68%\n",
      "Val Loss: 0.5871, Val Acc: 77.72%\n",
      "Epoch 19/50:\n",
      "Train Loss: 0.1874, Train Acc: 93.76%\n",
      "Val Loss: 0.7000, Val Acc: 76.68%\n",
      "Epoch 20/50:\n",
      "Train Loss: 0.1204, Train Acc: 96.10%\n",
      "Val Loss: 0.1984, Val Acc: 91.71%\n",
      "Epoch 21/50:\n",
      "Train Loss: 0.0894, Train Acc: 96.88%\n",
      "Val Loss: 0.0844, Val Acc: 95.34%\n",
      "Epoch 22/50:\n",
      "Train Loss: 0.0887, Train Acc: 96.23%\n",
      "Val Loss: 0.0763, Val Acc: 95.85%\n",
      "Epoch 23/50:\n",
      "Train Loss: 0.0869, Train Acc: 96.75%\n",
      "Val Loss: 0.0629, Val Acc: 95.85%\n",
      "Epoch 24/50:\n",
      "Train Loss: 0.0803, Train Acc: 97.01%\n",
      "Val Loss: 0.0652, Val Acc: 95.85%\n",
      "Epoch 25/50:\n",
      "Train Loss: 0.2312, Train Acc: 96.75%\n",
      "Val Loss: 0.0526, Val Acc: 97.41%\n",
      "Epoch 26/50:\n",
      "Train Loss: 0.1262, Train Acc: 96.36%\n",
      "Val Loss: 0.0968, Val Acc: 95.34%\n",
      "Epoch 27/50:\n",
      "Train Loss: 0.1332, Train Acc: 95.97%\n",
      "Val Loss: 0.1952, Val Acc: 93.26%\n",
      "Epoch 28/50:\n",
      "Train Loss: 0.1105, Train Acc: 95.84%\n",
      "Val Loss: 0.0793, Val Acc: 96.37%\n",
      "Epoch 29/50:\n",
      "Train Loss: 0.0903, Train Acc: 96.62%\n",
      "Val Loss: 0.0694, Val Acc: 96.37%\n",
      "Epoch 30/50:\n",
      "Train Loss: 0.0752, Train Acc: 97.27%\n",
      "Val Loss: 0.0746, Val Acc: 96.37%\n",
      "Epoch 31/50:\n",
      "Train Loss: 0.0742, Train Acc: 96.88%\n",
      "Val Loss: 0.0764, Val Acc: 96.37%\n",
      "Epoch 32/50:\n",
      "Train Loss: 0.0871, Train Acc: 97.14%\n",
      "Val Loss: 0.0656, Val Acc: 96.37%\n",
      "Epoch 33/50:\n",
      "Train Loss: 0.1919, Train Acc: 97.27%\n",
      "Val Loss: 0.0792, Val Acc: 96.37%\n",
      "Epoch 34/50:\n",
      "Train Loss: 0.1085, Train Acc: 96.49%\n",
      "Val Loss: 0.0916, Val Acc: 96.37%\n",
      "Epoch 35/50:\n",
      "Train Loss: 0.0815, Train Acc: 97.14%\n",
      "Val Loss: 0.0809, Val Acc: 96.37%\n",
      "Epoch 36/50:\n",
      "Train Loss: 0.0799, Train Acc: 96.49%\n",
      "Val Loss: 0.0663, Val Acc: 96.89%\n",
      "Epoch 37/50:\n",
      "Train Loss: 0.0706, Train Acc: 97.14%\n",
      "Val Loss: 0.0790, Val Acc: 96.37%\n",
      "Epoch 38/50:\n",
      "Train Loss: 0.0787, Train Acc: 97.40%\n",
      "Val Loss: 0.0711, Val Acc: 96.37%\n",
      "Epoch 39/50:\n",
      "Train Loss: 0.0630, Train Acc: 97.40%\n",
      "Val Loss: 0.0728, Val Acc: 96.37%\n",
      "Epoch 40/50:\n",
      "Train Loss: 0.0690, Train Acc: 97.66%\n",
      "Val Loss: 0.0713, Val Acc: 96.37%\n",
      "Epoch 41/50:\n",
      "Train Loss: 0.0734, Train Acc: 97.53%\n",
      "Val Loss: 0.0713, Val Acc: 96.37%\n",
      "Epoch 42/50:\n",
      "Train Loss: 0.0597, Train Acc: 97.92%\n",
      "Val Loss: 0.0798, Val Acc: 96.37%\n",
      "Epoch 43/50:\n",
      "Train Loss: 0.0762, Train Acc: 97.14%\n",
      "Val Loss: 0.0685, Val Acc: 96.37%\n",
      "Epoch 44/50:\n",
      "Train Loss: 0.0692, Train Acc: 97.01%\n",
      "Val Loss: 0.0653, Val Acc: 96.37%\n",
      "Epoch 45/50:\n",
      "Train Loss: 0.0656, Train Acc: 97.92%\n",
      "Val Loss: 0.0690, Val Acc: 96.37%\n",
      "Epoch 46/50:\n",
      "Train Loss: 0.0694, Train Acc: 97.66%\n",
      "Val Loss: 0.0662, Val Acc: 96.89%\n",
      "Epoch 47/50:\n",
      "Train Loss: 0.0638, Train Acc: 97.92%\n",
      "Val Loss: 0.0647, Val Acc: 96.89%\n",
      "Epoch 48/50:\n",
      "Train Loss: 0.0695, Train Acc: 97.92%\n",
      "Val Loss: 0.0660, Val Acc: 96.37%\n",
      "Epoch 49/50:\n",
      "Train Loss: 0.0613, Train Acc: 97.79%\n",
      "Val Loss: 0.0724, Val Acc: 96.37%\n",
      "Epoch 50/50:\n",
      "Train Loss: 0.0626, Train Acc: 97.66%\n",
      "Val Loss: 0.0728, Val Acc: 96.37%\n",
      "Meilleure précision de validation: 97.41%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Entraînement\n",
    "def train(epochs=50):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    \n",
    "    best_val_acc = 0\n",
    "    \n",
    "    for epoch in tqdm(range(epochs), desc=\"Entraînement\"):\n",
    "        # Phase d'entraînement\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for batch in train_loader:\n",
    "            features = batch['features'].to(device)\n",
    "            targets = batch['gesture_id'].to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(features)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "        \n",
    "        train_acc = 100. * correct / total\n",
    "        \n",
    "        # Phase de validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                features = batch['features'].to(device)\n",
    "                targets = batch['gesture_id'].to(device)\n",
    "                \n",
    "                outputs = model(features)\n",
    "                loss = criterion(outputs, targets)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += targets.size(0)\n",
    "                correct += predicted.eq(targets).sum().item()\n",
    "        \n",
    "        val_acc = 100. * correct / total\n",
    "        \n",
    "        # Affichage des métriques\n",
    "        print(f\"Epoch {epoch+1}/{epochs}:\")\n",
    "        print(f\"Train Loss: {train_loss/len(train_loader):.4f}, Train Acc: {train_acc:.2f}%\")\n",
    "        print(f\"Val Loss: {val_loss/len(val_loader):.4f}, Val Acc: {val_acc:.2f}%\")\n",
    "        \n",
    "        # Mise à jour du scheduler\n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        # Sauvegarde du meilleur modèle\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), 'best_leap_model.pth')\n",
    "    \n",
    "    print(f\"Meilleure précision de validation: {best_val_acc:.2f}%\")\n",
    "\n",
    "\n",
    "train(epochs=50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
